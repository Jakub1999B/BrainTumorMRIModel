# -*- coding: utf-8 -*-
"""load_images.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ETeo142LrnHP_4aNTp1L-pIc3XKG4gXD
"""

import os
import sys
import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow import keras
from skimage import color
from skimage import io
import sklearn
from tqdm import tqdm
import cv2
import seaborn as sns
from keras import layers
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import datasets, layers, models
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
import argparse
from tensorflow.keras.utils import to_categorical
from imutils import paths
from tensorflow.keras.optimizers import SGD
from keras import Sequential

def normalization(image,label):
    image = tf.cast(image/255. ,tf.float32)
    return image,label

def load_datasets(image_size, train_path, test_path, batch_size):
  train_dataset = tf.keras.preprocessing.image_dataset_from_directory(
              train_path,
              labels="inferred",
              label_mode="categorical",
              color_mode="grayscale",
              batch_size=batch_size,
              image_size=image_size,
              shuffle=True,
              seed=40,
              validation_split=0.1,
              subset="training",
              interpolation="bilinear"
  )

  val_dataset = tf.keras.preprocessing.image_dataset_from_directory(
              train_path,
              labels="inferred",
              label_mode="categorical",
              color_mode="grayscale",
              batch_size=batch_size,
              image_size=image_size,
              shuffle=True,
              seed=40,  
              validation_split=0.1,
              subset="validation",
              interpolation="bilinear"
  )

  test_dataset = tf.keras.preprocessing.image_dataset_from_directory(
              test_path,
              labels="inferred",
              label_mode="categorical",
              color_mode="grayscale",
              batch_size=1,
              image_size=image_size,
              shuffle=True,
              interpolation="bilinear"
  )


  train_dataset = train_dataset.map(normalization)
  test_dataset = test_dataset.map(normalization)
  val_dataset = val_dataset.map(normalization)

  return train_dataset, val_dataset, test_dataset