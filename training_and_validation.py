# -*- coding: utf-8 -*-
"""training_and_validation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qHsi3u4y-RoMY86Mk79UUtofLpIIyGn-
"""

import os
import sys
sys.path.append("/content/drive/MyDrive/BrainTumorMRIModel")
import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow import keras
from skimage import color
from skimage import io
import sklearn
from tqdm import tqdm
import cv2
import seaborn as sns
from keras import layers
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import datasets, layers, models
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
import argparse
from tensorflow.keras.utils import to_categorical
from imutils import paths
from tensorflow.keras.optimizers import SGD
from keras import Sequential

# LOSS FUNCTION & OPTIMIZER

loss_fn = tf.keras.losses.CategoricalCrossentropy()
optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)
metric = tf.keras.metrics.CategoricalAccuracy('accuracy')

#DEFINING METRICS
train_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)
train_accuracy = tf.keras.metrics.CategoricalAccuracy('train_accuracy')
val_loss = tf.keras.metrics.Mean('val_loss', dtype=tf.float32)
val_accuracy = tf.keras.metrics.CategoricalAccuracy('val_accuracy')

# SUMMARIES FOR TENSORBOARD

import datetime

current_time = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
train_log_dir = 'logs/gradient_tape/' + current_time + '/train'
val_log_dir = 'logs/gradient_tape/' + current_time + '/val'
train_summary_writer = tf.summary.create_file_writer(train_log_dir)
val_summary_writer = tf.summary.create_file_writer(val_log_dir)

# TRAIN AND VALIDATION FUNCTIONS

def train_step(model, optimizer, x_train, y_train):
  with tf.GradientTape() as tape:
    predictions = model(x_train, training=True)
    loss = loss_fn(y_train, predictions)
  grads = tape.gradient(loss, model.trainable_variables)
  optimizer.apply_gradients(zip(grads, model.trainable_variables))

  train_loss(loss) 
  train_accuracy(y_train, predictions)

def val_step(model, x_val, y_val):
  predictions = model(x_val)
  loss = loss_fn(y_val, predictions)

  val_loss(loss)
  val_accuracy(y_val, predictions)

def train_and_val(model, epochs, optimizer, train_dataset, val_dataset):
  train_acc_recap =[]
  train_loss_recap = []
  val_acc_recap = []
  val_loss_recap = []

  for epoch in range(epochs):
    for (x_train, y_train) in train_dataset:
      train_step(model, optimizer, x_train, y_train)
    with train_summary_writer.as_default():
      tf.summary.scalar('loss', train_loss.result(), step=epoch)
      tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)

    for (x_val, y_val) in val_dataset:
      val_step(model, x_val, y_val)
    with val_summary_writer.as_default():
      tf.summary.scalar('loss', val_loss.result(), step=epoch)
      tf.summary.scalar('accuracy', val_accuracy.result(), step=epoch)

    template = 'Epoch {}, Loss: {}, Accuracy: {}, Validation Loss: {}, Validation Accuracy: {}'
    print(template.format(epoch+1,
                          train_loss.result(), 
                          train_accuracy.result()*100,
                          val_loss.result(), 
                          val_accuracy.result()*100))
    
    train_acc_recap.append(train_accuracy.result())
    train_loss_recap.append(train_loss.result())
    val_acc_recap.append(val_accuracy.result())
    val_loss_recap.append(val_loss.result())

    # Reset metrics every epoch
    train_loss.reset_states()
    val_loss.reset_states()
    train_accuracy.reset_states()
    val_accuracy.reset_states()


  return model, train_acc_recap, train_loss_recap, val_acc_recap, val_loss_recap

# TRAIN AND VALIDATION FUNCTIONS WITH AUGMENTATION
import time

def train_step_aug(model, optimizer, x_train, y_train, generator):
  z = generator.flow(x_train, y_train, batch_size=32)
  x_train = z[0][0]
  y_train = z[0][1]
  with tf.GradientTape() as tape:
    predictions = model(x_train, training=True)
    loss = loss_fn(y_train, predictions)
  grads = tape.gradient(loss, model.trainable_variables)
  optimizer.apply_gradients(zip(grads, model.trainable_variables))

  train_loss(loss) 
  train_accuracy(y_train, predictions)

def val_step(model, x_val, y_val):
  predictions = model(x_val)
  loss = loss_fn(y_val, predictions)

  val_loss(loss)
  val_accuracy(y_val, predictions)

def train_and_val_aug(model, epochs, optimizer, train_dataset, val_dataset, generator):
  t1 = time.time()
  train_acc_recap =[]
  train_loss_recap = []
  val_acc_recap = []
  val_loss_recap = []

  for epoch in range(epochs):
    for (x_train, y_train) in train_dataset:
      train_step_aug(model, optimizer, x_train, y_train, generator)
    with train_summary_writer.as_default():
      tf.summary.scalar('loss', train_loss.result(), step=epoch)
      tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)

    for (x_val, y_val) in val_dataset:
      val_step(model, x_val, y_val)
    with val_summary_writer.as_default():
      tf.summary.scalar('loss', val_loss.result(), step=epoch)
      tf.summary.scalar('accuracy', val_accuracy.result(), step=epoch)

    template = 'Epoch {}, Loss: {}, Accuracy: {}, Validation Loss: {}, Validation Accuracy: {}'
    print(template.format(epoch+1,
                          train_loss.result(), 
                          train_accuracy.result()*100,
                          val_loss.result(), 
                          val_accuracy.result()*100))
    
    train_acc_recap.append(train_accuracy.result())
    train_loss_recap.append(train_loss.result())
    val_acc_recap.append(val_accuracy.result())
    val_loss_recap.append(val_loss.result())

    # Reset metrics every epoch
    train_loss.reset_states()
    val_loss.reset_states()
    train_accuracy.reset_states()
    val_accuracy.reset_states()
  t2 = time.time()
  tim = t2-t1
  print(f'Time is {tim/60} min')


  return model, train_acc_recap, train_loss_recap, val_acc_recap, val_loss_recap